# base
train_path = data/datasets3/kbp17/kbp17_train_context@1.json
valid_path = data/datasets3/kbp17/kbp17_test_context@1.json
types_path = data/datasets3/kbp17/kbp17_types.json
save_path = data/ssn/kbp17
log_path = data/ssn/kbp17
label = ablation
init_eval = False
final_eval = False
save_optimizer = False
store_predictions = False
store_examples = False
example_count = None
train_log_iter = 1
sampling_processes = 4
train_batch_size = 8
eval_batch_size = 8
epochs = 60
split_epoch = 5
match_warmup_epoch = 0
lr = 2e-05
lr_warmup = 0.1
weight_decay = 0.01
max_grad_norm = 1.0
match_solver = hungarian
type_loss = celoss
nil_weight = -1.0
match_boundary_weight = 3.0
match_class_weight = 3.0
loss_boundary_weight = 3.0
loss_class_weight = 3.0
deeply_weight = same
copy_weight = True
local_rank = -1
world_size = -1
wordvec_path = /home/wsh/ebd/glove.6B.100d.txt
tokenizer_path = /home/wsh/trf/bert-base-cased
model_path = /home/wsh/trf/bert-base-cased
lowercase = False
debug = False
model_type = ssn
cpu = False
prop_drop = 0.1
freeze_transformer = False
no_overlapping = False
no_partial_overlapping = False
no_duplicate = False
cls_threshold = 0.0
boundary_threshold = 0.0
use_topk_query = True
use_msf = True
fpn_layer = 16
fpn_type = uni
num_dec_layer = 3
entity_queries_num = 60
pos_size = 25
char_lstm_layers = 1
char_size = 50
char_lstm_drop = 0.1
lstm_drop = 0.1
use_glove = True
use_pos = True
use_char_lstm = True
use_lstm = True
pool_type = max
use_aux_loss = True
seed = 47
cache_path = None